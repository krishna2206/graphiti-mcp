# Graphiti MCP Server Environment Configuration

# Google Gemini API Configuration (REQUIRED)
# Get your API key from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# Optional: Google Cloud Project Configuration
# GOOGLE_PROJECT_ID=your-project-id
# GOOGLE_LOCATION=us-central1

# FalkorDB Database Configuration
# FalkorDB is the graph database backend (Redis-based)
FALKORDB_URI=redis://localhost:6379
FALKORDB_PASSWORD=
FALKORDB_DATABASE=default_db

# Optional: Group ID for namespacing graph data
GRAPHITI_GROUP_ID=main

# ==============================================================================
# Concurrency Control - CRITICAL FOR RATE LIMITING
# ==============================================================================
# Controls how many episodes can be processed simultaneously
# Each episode involves multiple LLM calls (extraction, deduplication, edges, etc.)
# For a long text, this can generate 30-100+ API calls per episode!
#
# TUNING GUIDELINES based on Gemini API Rate Limits:
#
# Gemini Free Tier (15 RPM):
#   SEMAPHORE_LIMIT=1-2  ⚠️ RECOMMENDED for long texts
#   SEMAPHORE_LIMIT=3-5  (For short texts only)
#
# Gemini Pay-as-you-go (60+ RPM):
#   SEMAPHORE_LIMIT=5-10
#
# Gemini High Volume (1,000+ RPM):
#   SEMAPHORE_LIMIT=15-30
#
# SYMPTOMS:
# - Too high: "429 Too Many Requests" errors (rate limit exceeded)
# - Too low: Slow processing, underutilized API quota
#
# ⚠️ WARNING: With long texts and SEMAPHORE_LIMIT=10, you'll hit rate limits!
# Default: 3 (conservative for free tier)
SEMAPHORE_LIMIT=3

# FalkorDB Browser UI (1=enabled, 0=disabled)
BROWSER=1

# Optional: Path configuration for Docker
# PATH=/root/.local/bin:${PATH}
